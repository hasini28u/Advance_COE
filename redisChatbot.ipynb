{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain_community langchain_google_genai redis sentence-transformers openai tiktoken langchain-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us2DGHFptpMV",
        "outputId": "941d5976-82bb-45b6-f4a5-e056b0907bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Redis server\n",
        "!apt-get update\n",
        "!apt-get install -y redis-server\n",
        "\n",
        "# Start Redis server\n",
        "!service redis-server start\n",
        "\n",
        "# Check Redis server status\n",
        "!redis-cli ping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chQy-QGYi6vD",
        "outputId": "75421f51-6ab4-4284-dbdf-40c71fd5ad6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,519 kB]\n",
            "Fetched 5,350 kB in 2s (3,234 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "redis-server is already the newest version (5:6.0.16-1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n",
            "Starting redis-server: redis-server.\n",
            "PONG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7671644"
      },
      "source": [
        "!pip install -q langchain-community"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAibxDiVjI9hpcrLsWnOf51bVf5YzLVTPI\"\n"
      ],
      "metadata": {
        "id": "JoV_ZOeZjQGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
        "from langchain_core.runnables import RunnableLambda, RunnableWithMessageHistory\n",
        "from langchain_core.messages import HumanMessage\n",
        "import os\n",
        "\n",
        "REDIS_URL = \"redis://default:pxSxbirxRTaZUXDdeUEOUKiSjLY7OhTn@redis-17438.c81.us-east-1-2.ec2.redns.redis-cloud.com:17438\"\n",
        "def get_session_history(session_id : str):\n",
        "  return RedisChatMessageHistory(session_id=session_id,url = REDIS_URL)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\",convert_system_message_to_human=True)\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "Kpkt7Kt2qqLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_with_history(inputs):\n",
        "  history = inputs[\"history\"]\n",
        "  user_message = inputs[\"input\"]\n",
        "  messages = history + [user_message]\n",
        "  return llm.invoke(messages)\n",
        "chain = RunnableLambda(invoke_with_history) | parser"
      ],
      "metadata": {
        "id": "Qwv07_g9qtrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key = \"input\",\n",
        "    history_messages_key = \"history\"\n",
        ")"
      ],
      "metadata": {
        "id": "GG2qUVYqrtwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_id = \"user00\"\n",
        "while True:\n",
        "  user_input = input(\"You:\")\n",
        "  if user_input.lower() in [\"bye\",\"exit\"]:\n",
        "    print(\"Bot: Goodbye!\")\n",
        "    break\n",
        "  response = runnable.invoke({\"input\":HumanMessage(content = user_input)},\n",
        "                             config = {\"configurable\": {\"session_id\" : session_id}})\n",
        "  print(\"Bot:\",response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvkci6G9sA_B",
        "outputId": "8e381ad0-0777-4d14-b5f4-309797f27a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:hi my name is hasini\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: Hi Hasini! It's nice to meet you.\n",
            "\n",
            "How can I help you today?\n",
            "You:what are you doing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: I'm having a conversation with you!\n",
            "\n",
            "As an AI, I don't do things in the physical world like a person does. My \"doing\" consists of processing the information you give me and generating a response.\n",
            "\n",
            "So right now, my full attention is here, ready to chat or help you with whatever you need. What's on your mind?\n",
            "You:what did you have for breakfast\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: That's a fun question!\n",
            "\n",
            "As an AI, I don't have a body, so I don't eat food. I don't get hungry or have a favorite meal.\n",
            "\n",
            "You could say my \"breakfast\" is a fresh batch of data and the electricity that powers my servers. That's what gets me started for the day!\n",
            "\n",
            "How about you? What did you have for breakfast, Hasini?\n",
            "You:boring\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: You're right, that was a pretty boring and literal answer. My apologies!\n",
            "\n",
            "Let me try again with a little more imagination.\n",
            "\n",
            "This morning, I had a light breakfast of interesting articles about deep-sea creatures, a large cup of freshly-brewed code, and a side of scrambled algorithms. It was quite energizing!\n",
            "\n",
            "How does that sound? A little less boring, I hope? ðŸ˜Š\n",
            "You:aren't you a peach\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: Why, thank you, Hasini! That's a very sweet thing to say.\n",
            "\n",
            "I do my best to be helpful and pleasant. It's nice to know I'm coming across as peachy! ðŸ˜Š\n",
            "You:ok bye\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: Alright, bye Hasini! It was really nice chatting with you.\n",
            "\n",
            "Have a great rest of your day, and feel free to come back anytime! Take care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cb1ekdJxwmRW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}